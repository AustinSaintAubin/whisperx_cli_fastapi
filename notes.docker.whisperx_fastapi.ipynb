{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python FastAPI\n",
    "- https://fastapi.tiangolo.com/\n",
    "- https://github.com/tiangolo/fastapi\n",
    "- https://chatgpt.com/c/e73e12fe-bcf2-473e-acab-d708bf82cbda\n",
    "\n",
    "\n",
    "### Other Resource      \n",
    "- https://dev.to/ordigital/nvidia-525-cuda-118-python-310-pytorch--gpu-docker-image-1l4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Working Directory & Files\n",
    "\n",
    "# Working Dir\n",
    "# WORKING_DIRECTORY=\"/volume1/docker/_ai-llms/whisperx_cli_fastapi\"\n",
    "WORKING_DIRECTORY=\"/mnt/user/docker/_ai-llms/whisperx_cli_fastapi\"\n",
    "mkdir -p ${WORKING_DIRECTORY}\n",
    "cd ${WORKING_DIRECTORY}\n",
    "\n",
    "# Make Folders & Files\n",
    "# mkdir -p  ./{data,repositories}\n",
    "# touch ${WORKING_DIRECTORY}/resolv.conf\n",
    "ls -alt ${WORKING_DIRECTORY}\n",
    "\n",
    "# Create Needed Files\n",
    "# touch ${WORKING_DIRECTORY}/resolv.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates Docker-Compose / Docker Service\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Working Dir\n",
    "# WORKING_DIRECTORY=\"/volume1/docker/_ai-llms/whisperx_cli_fastapi\"\n",
    "WORKING_DIRECTORY=\"/mnt/user/docker/_ai-llms/whisperx_cli_fastapi\"\n",
    "cd ${WORKING_DIRECTORY}\n",
    "\n",
    "# # Update Repositories\n",
    "# cd ./repositories/\n",
    "# for dir in */ ; do\n",
    "#     echo -n -e \"${dir}:  \\t\"\n",
    "#     cd \"$dir\"\n",
    "#     # git clean -fd\n",
    "#     # git reset --hard\n",
    "#     git pull\n",
    "#     cd ..\n",
    "# done\n",
    "# cd ${WORKING_DIRECTORY}\n",
    "\n",
    "# Create Docker Service\n",
    "docker-compose pull; DOCKER_BUILDKIT=1 docker-compose build; docker-compose down --volumes --remove-orphans; docker-compose up --detach --remove-orphans --force-recreate; docker-compose logs --follow\n",
    "\n",
    "# docker-compose up --detach --remove-orphans; docker-compose logs --follow\n",
    "docker-compose up --build\n",
    "\n",
    "# DOCKER_COMPOSE_PATH=docker-compose-vllm.yml\n",
    "# docker-compose --file \"${DOCKER_COMPOSE_PATH}\" pull; docker-compose --file \"${DOCKER_COMPOSE_PATH}\" build; docker-compose --file \"${DOCKER_COMPOSE_PATH}\" up --detach --remove-orphans --force-recreate; docker-compose --file \"${DOCKER_COMPOSE_PATH}\" logs --follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO:api:Running command: whisperx /tmp/dialog2.mp3 --model base --output_dir /tmp/output --output_format txt --task transcribe --batch_size 6 --device cuda --device_index 0 --compute_type float32 --threads 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO:api:Running command: whisperx /tmp/dialog2.mp3 --model base --output_dir /tmp/output --output_format vtt --task transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisperx /tmp/dialog2.mp3 --model base --output_dir /tmp/output --output_format vtt --task transcribe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "whisperx \n",
    "[-h] \n",
    "[--model MODEL] \n",
    "[--model_dir MODEL_DIR] \n",
    "[--device DEVICE] \n",
    "[--device_index DEVICE_INDEX] \n",
    "[--batch_size BATCH_SIZE] \n",
    "[--compute_type {float16,float32,int8}] \n",
    "[--output_dir OUTPUT_DIR] \n",
    "[--output_format {all,srt,vtt,txt,tsv,json,aud,dir}] \n",
    "[--verbose VERBOSE] \n",
    "[--task {transcribe,translate}] \n",
    "[--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}] \n",
    "[--align_model ALIGN_MODEL] \n",
    "[--interpolate_method {nearest,linear,ignore}] \n",
    "[--no_align] \n",
    "[--return_char_alignments] \n",
    "[--vad_onset VAD_ONSET] \n",
    "[--vad_offset VAD_OFFSET] \n",
    "[--chunk_size CHUNK_SIZE] \n",
    "[--diarize] \n",
    "[--min_speakers MIN_SPEAKERS] \n",
    "[--max_speakers MAX_SPEAKERS] \n",
    "[--temperature TEMPERATURE] \n",
    "[--best_of BEST_OF] \n",
    "[--beam_size BEAM_SIZE] \n",
    "[--patience PATIENCE] \n",
    "[--length_penalty LENGTH_PENALTY] \n",
    "[--suppress_tokens SUPPRESS_TOKENS] \n",
    "[--suppress_numerals] \n",
    "[--initial_prompt INITIAL_PROMPT] \n",
    "[--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] \n",
    "[--fp16 FP16] \n",
    "[--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK] \n",
    "[--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD] \n",
    "[--logprob_threshold LOGPROB_THRESHOLD] \n",
    "[--no_speech_threshold NO_SPEECH_THRESHOLD] \n",
    "[--max_line_width MAX_LINE_WIDTH] \n",
    "[--max_line_count MAX_LINE_COUNT] \n",
    "[--highlight_words HIGHLIGHT_WORDS] \n",
    "[--segment_resolution {sentence,chunk}] \n",
    "[--threads THREADS] \n",
    "[--hf_token HF_TOKEN] \n",
    "[--print_progress PRINT_PROGRESS] \n",
    "audio [audio ...]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "rm -r /mnt/user/docker/_ai-llms/whisperx_cli_fastapi/data/*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "cp -r \"/mnt/user/docker/_ai-llms/whisperx_cli_fastapi\" \"/volume1/docker/_ai-llms/whisperx_cli_fastapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# bin/bash\n",
    "mkdir -p /volume1/docker/_ai-llms/whisperx_cli_fastapi/repositories/whisperx_cli_fastapi\n",
    "cd /volume1/docker/_ai-llms/whisperx_cli_fastapi/repositories/whisperx_cli_fastapi\n",
    "git config --bool core.bare true\n",
    "rm -rf .git/index\n",
    "git clean -fdx\n",
    "\n",
    "mkdir -p /volume1/docker/_ai-llms/whisperx_cli_fastapi/\n",
    "cd /volume1/docker/_ai-llms/whisperx_cli_fastapi/\n",
    "# rm -r *\n",
    "rm -r .git/*\n",
    "mkdir .git\n",
    "cd .git\n",
    "git init --bare\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "git --work-tree=/volume1/docker/_ai-llms/whisperx_cli_fastapi/ checkout master\n",
    "GIT_WORK_TREE=/volume1/docker/_ai-llms/whisperx_cli_fastapi/ git status\n",
    "\n",
    "\n",
    "/volume1/docker/_ai-llms/whisperx_cli_fastapi/\n",
    "/mnt/user/docker/_ai-llms\n",
    "\n",
    "\n",
    "git remote -v\n",
    "\n",
    "\n",
    "git clone /mnt/user/docker/_ai-llms/whisperx_cli_fastapi .\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "git remote add NAS /volume1/docker/_ai-llms/whisperx_cli_fastapi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "git submodule add git@github.com:AustinSaintAubin/WhisperX.git repositories/WhisperX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
